---
title: From tinygrad to PyTorch
description: Training a tinygrad MNIST model and transferring the weights to PyTorch.
author: Kelly To
date: '2024-09-09'
categories: [PyTorch, tinygrad, MNIST]
css: columns.css
---

::::: {.multiple}

-----

:::: {.columns .column-screen-inset}
::: column
This is the second post of my series documenting my explorations with comparing PyTorch and tinygrad. Like the first post, [From PyTorch to tinygrad](/blog/posts/1_from_pytorch_to_tinygrad.qmd), I will be using the simple model from [tinygrad's MNIST tutorial](https://docs.tinygrad.org/mnist/) and a PyTorch version of the model that I wrote. The experiment in this post does the previous experiment the other way around (training the tinygrad model and transferring the resulting weights to the PyTorch model to see if the two models produce the same probabilities).

I have the models in two files, 'tinygrad_MNIST_start.ipynb' and 'pytorch_MNIST_end.ipynb'. Below is a side-by-side comparison of the tinygrad and PyTorch code.
:::
::::

<!---------- Device configuration ---------->

:::: {.columns .column-screen-inset}
::: column
## Device configuration
###### The device configuration is the same as the previous post.
:::
::::

:::: {.columns .column-screen-inset}
::: column
###### For tinygrad, the default device is based on your system. In this case, it is METAL.
#### tinygrad
```python
from tinygrad import Device

print(Device.DEFAULT)
```
###### METAL
:::
::: column
###### The default device for PyTorch is CPU, but since I am using an M3 Max Macbook Pro, I switched it to MPS for acceleration.
#### PyTorch
```python
import torch

if torch.backends.mps.is_available():
    device = torch.device("mps")
else:
    device = torch.device("cpu")  
print(device)
```
###### mps
:::
::::

<!---------- Model ---------->

:::: {.columns .column-screen-inset}
::: column
## Model
###### The model is the same as the previous post: a convolutional neural network with two convolutional layers and a linear layer. The convolutional layers have 32 and 64 filters, respectively. The linear layer has 10 output units, one for each digit. 
:::
::::

:::: {.columns .column-screen-inset}
::: column
###### The tinygrad model is a simple class. Instead of having a forward method, it instead uses a __call__ method that functions like PyTorch's forward method.
#### tinygrad
```python
from tinygrad import Tensor, nn

class Model:
  def __init__(self):
    self.l1 = nn.Conv2d(1, 32, kernel_size=(3,3))
    self.l2 = nn.Conv2d(32, 64, kernel_size=(3,3))
    self.l3 = nn.Linear(1600, 10)

  def __call__(self, x:Tensor) -> Tensor:
    x = self.l1(x).relu().max_pool2d((2,2))
    x = self.l2(x).relu().max_pool2d((2,2))
    return self.l3(x.flatten(1).dropout(0.5))
```
:::
::: column
###### The PyTorch model inherits from nn.Module, which is a base class in PyTorch for creating models. It calls a forward method to apply the model to the input.
#### PyTorch
```python
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.l1 = nn.Conv2d(1, 32, kernel_size=(3,3))
        self.l2 = nn.Conv2d(32, 64, kernel_size=(3,3))
        self.l3 = nn.Linear(1600, 10)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.l1(x)), (2,2))
        x = F.max_pool2d(F.relu(self.l2(x)), (2,2))
        return self.l3(F.dropout(x.flatten(1), 0.5, self.training))
```
:::
::::

<!---------- Get the MNIST dataset ---------->

:::: {.columns .column-screen-inset}
::: column
## Get the MNIST dataset
###### Getting the MNIST dataset is the same as the previous post. To get the dataset, I used tinygrad's mnist function for both models to keep things simple. I did have to convert the tinygrad tensors that were returned by the function into PyTorch tensors to use them in the PyTorch model. 
:::
::::

:::: {.columns .column-screen-inset}
::: column
#### tinygrad
```python
from tinygrad.nn.datasets import mnist

X_train, Y_train, X_test, Y_test = mnist()
print(X_train.shape, X_train.dtype, Y_train.shape, Y_train.dtype)
```
###### (60000, 1, 28, 28) dtypes.uchar (60000,) dtypes.uchar
:::
::: column
#### PyTorch
```python
from tinygrad.nn.datasets import mnist

X_train, Y_train, X_test, Y_test = mnist()

# Convert tinygrad Tensors to PyTorch tensors 
X_train = torch.from_numpy(X_train.numpy()).float().reshape(-1, 1, 28, 28).to(device) 
Y_train = torch.from_numpy(Y_train.numpy()).long().to(device) 
X_test = torch.from_numpy(X_test.numpy()).float().reshape(-1, 1, 28, 28).to(device) 
Y_test = torch.from_numpy(Y_test.numpy()).long().to(device) 

print(X_train.shape, X_train.dtype, Y_train.shape, Y_train.dtype)
```
###### torch.Size([60000, 1, 28, 28]) torch.float32 torch.Size([60000]) torch.int64
:::
::::

<!---------- Use the model ---------->

:::: {.columns .column-screen-inset}
::: column
## Use the model
###### The models are created and evaluated in the same way as the previous post.
:::
::::

:::: {.columns .column-screen-inset}
::: column
#### tinygrad
```python
model = Model()
acc = (model(X_test).argmax(axis=1) == Y_test).mean()
print(acc.item())   
```
###### 0.12680000066757202
:::
::: column
#### PyTorch
```python 
model = Model().to(device)
acc = (model(X_test).argmax(axis=1) == Y_test).float().mean()
print(acc.item())  
```
###### 0.1168999969959259
:::
::::

:::: {.columns .column-screen-inset}
::: column
#### tinygrad
###### The model is trained using the Adam optimizer and the sparse categorical cross entropy loss function. It is trained for 7000 steps and is evaluated on the test set after every 100 steps. 
### Train the model
###### It took 1 minute and 24.6 seconds to train the model. This is slower than the PyTorch model, which took 50.4 seconds to train, but is still pretty comparable.
###### One issue I ran into was tracking train accuracy. I've commented out the related code. When using the entire training dataset, the line of code defining train_acc gives me this runtime error: '4426058304'. When using half of the training dataset, the same line gives me this memory error: 'Metal OOM while allocating size=2595840000'.
###### If I only use a third of the training dataset, it runs just fine, completing training in 58.6s. 
```python
optim = nn.optim.Adam(nn.state.get_parameters(model))
batch_size = 128
def step():
    Tensor.training = True  # makes dropout work
    samples = Tensor.randint(batch_size, high=X_train.shape[0])
    X, Y = X_train[samples], Y_train[samples]
    optim.zero_grad()
    loss = model(X).sparse_categorical_crossentropy(Y).backward()
    optim.step()
    return loss
```
```python
from tinygrad import TinyJit

jit_step = TinyJit(step)
```
```python
train_losses = []
test_losses = []

train_accuracies = []
test_accuracies = []

for step in range(7000):
    # Calculate train loss
    loss = jit_step()
    train_losses.append(loss.item())

    if step%100 == 0:
        Tensor.training = False     # Disables dropout for evaluation

        # Calculate train accuracy
        #train_outputs = model(X_train)
        #train_acc = (train_outputs.argmax(axis=1) == Y_train).mean().item()
        #train_accuracies.append(train_acc)

        # Calculate test accuracy
        test_outputs = model(X_test)
        test_acc = (test_outputs.argmax(axis=1) == Y_test).mean().item()
        test_accuracies.append(test_acc)

        # Calculate test loss
        test_loss = test_outputs.sparse_categorical_crossentropy(Y_test).mean().item()
        test_losses.append(test_loss)

        #print(f"step {step:4d}, loss {loss.item():.2f}, train acc {train_acc*100.:.2f}%, test acc {test_acc*100.:.2f}%")
        print(f"step {step:4d}, loss {loss.item():.2f}, test acc {test_acc*100.:.2f}%")
```
###### step    0, loss 36.39, test acc 22.92%
###### step  100, loss 0.38, test acc 93.78%
###### step  200, loss 0.65, test acc 96.03%
###### step  300, loss 0.23, test acc 96.56%
###### ...
###### step 6600, loss 0.14, test acc 98.93%
###### step 6700, loss 0.07, test acc 98.90%
###### step 6800, loss 0.05, test acc 98.94%
###### step 6900, loss 0.03, test acc 98.88%
:::
::::

:::: {.columns .column-screen-inset}
::: column
### Plot the loss
```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(range(len(train_losses)), train_losses, label='Train Loss')
plt.plot(range(0, len(test_losses) * 100, 100), test_losses, label='Test Loss') # every 100 steps
plt.title('Tinygrad: Train and Test Loss')
plt.xlabel('Steps')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()
```
![](../images/2_from_tinygrad_to_pytorch/tinygrad_loss.png)
:::
::: column
### Plot the accuracy
###### Keep in mind that there is no train accuracy line due to the memory error.
###### When I used only a third of the training dataset, I was able to produce a plot that looks very similar to the accuracy plot of the [previous post](/blog/posts/1_from_pytorch_to_tinygrad.qmd).
```python
plt.figure(figsize=(10, 5))
plt.plot(range(0, len(train_accuracies) * 100, 100), train_accuracies, label='Train Accuracy')
plt.plot(range(0, len(test_accuracies) * 100, 100), test_accuracies, label='Test Accuracy')
plt.title('Tinygrad: Train and Test Accuracy')
plt.xlabel('Steps')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()
```
![](../images/2_from_tinygrad_to_pytorch/tinygrad_accuracy.png)
:::
::::

:::: {.columns .column-screen-inset}
::: column
### Save the weights
###### To use the weights from the tinygrad model in the PyTorch model, I saved the weights as a NumPy array.
```python
import numpy as np

tinygrad_weights = {
    'l1.weight': model.l1.weight.numpy(),
    'l1.bias': model.l1.bias.numpy(),
    'l2.weight': model.l2.weight.numpy(),
    'l2.bias': model.l2.bias.numpy(),
    'l3.weight': model.l3.weight.numpy(),
    'l3.bias': model.l3.bias.numpy()
}
np.save('tinygrad_weights.npy', tinygrad_weights)
```
:::
::::

:::: {.columns .column-screen-inset}
::: column
#### PyTorch
### Use the tinygrad weights
###### Then, in my PyTorch model, I loaded the tinygrad weights and set them as the weights of the model. 
```python
import numpy as np

loaded_weights = np.load('tinygrad_weights.npy', allow_pickle=True).item()

model.l1.weight.data = torch.tensor(loaded_weights['l1.weight']).to(device)
model.l1.bias.data = torch.tensor(loaded_weights['l1.bias']).to(device)
model.l2.weight.data = torch.tensor(loaded_weights['l2.weight']).to(device)
model.l2.bias.data = torch.tensor(loaded_weights['l2.bias']).to(device)
model.l3.weight.data = torch.tensor(loaded_weights['l3.weight']).to(device)
model.l3.bias.data = torch.tensor(loaded_weights['l3.bias']).to(device)
```
:::
::::

<!---------- Final Probabilities ---------->

:::: {.columns .column-screen-inset}
::: column
## Final Probabilities
###### When comparing the probabilities produced by both models, we can see that they are very similar with negligible variations that can be attributed to floating-point precision differences.
:::
::::

:::: {.columns .column-screen-inset}
::: column
#### tinygrad
```python
test_image = X_test[0:1]
tinygrad_probs = model(test_image).softmax().numpy()
print("tinygrad probabilities:", tinygrad_probs)
```
###### tinygrad probabilities: [[9.3983861e-09 6.8721730e-11 7.7753964e-07 5.7046219e-07 4.1008310e-13 8.9367888e-11 2.8149701e-17 9.9999869e-01 2.8185179e-10 4.4023501e-08]]
:::
::: column
#### PyTorch
```python
test_image = X_test[0:1]
model.eval()
with torch.no_grad():
    pytorch_probs = F.softmax(model(test_image), dim=1).cpu().numpy()
print("PyTorch probabilities:", pytorch_probs)
```
###### PyTorch probabilities: [[9.3983630e-09 6.8721799e-11 7.7754157e-07 5.7046429e-07 4.1008307e-13 8.9367916e-11 2.8149701e-17 9.9999857e-01 2.8185207e-10 4.4023473e-08]]
:::
::::

:::::
