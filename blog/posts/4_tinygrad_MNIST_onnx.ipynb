{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: From PyTorch to tinygrad using ONNX\n",
    "description: Training a PyTorch model and converting it to ONNX and then to tinygrad.\n",
    "author: Kelly To\n",
    "date: '2024-09-12'\n",
    "categories: [PyTorch, tinygrad, MNIST, ONNX]\n",
    "---\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post demonstrates how to use ONNX to get tinygrad to run a PyTorch model. This is an alternative to writing a whole tinygrad version of the PyTorch model you want to port, like we did in the post [From PyTorch to tinygrad](/blog/posts/1_from_pytorch_to_tinygrad.qmd).\n",
    "\n",
    "The PyTorch model I'm exporting is from the PyTorch file I used in that post, 'pytorch_MNIST_start.ipynb'. The tinygrad code is in a separate file that I made called 'tinygrad_MNIST_onnx.ipynb'. Below is the relevant code from the two files.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch\n",
    "## Export PyTorch model as an ONNX model\n",
    "###### In my 'pytorch_MNIST_start.ipynb' file, I added the following code to the end of the notebook to export the model as an ONNX model in a file called 'mnist_model.onnx'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "torch.onnx.export(model, \n",
    "                  dummy_input, \n",
    "                  \"mnist_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### tinygrad\n",
    "## Load ONNX model in tinygrad\n",
    "###### This loads the ONNX model in tinygrad and creates a callable object 'run_onnx' that can execute the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from extra.onnx import get_run_onnx\n",
    "\n",
    "model = onnx.load(\"mnist_model.onnx\")\n",
    "run_onnx = get_run_onnx(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count parameters\n",
    "###### I tweaked the 'count_parameters' function from the previous blog post, [Pretty Table for Parameters](/blog/posts/3_pretty_table_for_parameters.qmd), to work with ONNX models. Looking at the table, we can confirm that the ONNX model has the same number of parameters as the PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|  Modules  | Parameters |\n",
      "+-----------+------------+\n",
      "| l1.weight |    288     |\n",
      "|  l1.bias  |     32     |\n",
      "| l2.weight |   18432    |\n",
      "|  l2.bias  |     64     |\n",
      "| l3.weight |   16000    |\n",
      "|  l3.bias  |     10     |\n",
      "+-----------+------------+\n",
      "Total Trainable Params: 34826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(34826)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    # ONNX uses model.graph.initializer to iterate through the parameters (nodes)\n",
    "    for node in model.graph.initializer:\n",
    "        # ONNX uses np.prod() to calculate parameter count by multiplying the dimensions (node.dims = parameter shape)\n",
    "        num_params = np.prod(node.dims)\n",
    "        table.add_row([node.name, num_params])\n",
    "        total_params += num_params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\\n\")\n",
    "    return total_params\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MNIST dataset\n",
    "###### I imported the MNIST dataset to grab an image to use to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinygrad.nn.datasets import mnist\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = mnist()\n",
    "print(X_train.shape, X_train.dtype, Y_train.shape, Y_train.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final probabilities\n",
    "###### If you refer back to the final tinygrad probabilities in [From PyTorch to tinygrad](/blog/posts/1_from_pytorch_to_tinygrad.qmd), you will see that the values below are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tinygrad probabilities: [[2.6173244e-14 4.2464655e-14 6.4881434e-08 4.5528861e-09 2.0712009e-17\n",
      "  4.9732746e-11 1.3766536e-21 9.9999988e-01 8.9217121e-13 8.5283941e-10]]\n"
     ]
    }
   ],
   "source": [
    "# Select the first test image\n",
    "test_image = X_test[0:1]\n",
    "\n",
    "# Run the ONNX model using run_onnx function with the test image as input\n",
    "# The model expects an input with the key \"input.1\"\n",
    "onnx_output = run_onnx({\"input.1\": test_image})\n",
    "\n",
    "# Get the output tensor (single vector of 10 values, 1 for each digit class)\n",
    "output_tensor = list(onnx_output.values())[0]\n",
    "\n",
    "# Apply softmax and convert to numpy\n",
    "tinygrad_probs = output_tensor.softmax().numpy()\n",
    "\n",
    "# Print the resulting probabilities\n",
    "print(\"tinygrad probabilities:\", tinygrad_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
